---
title: "Chapter 13: Logistic regression"
author: "Wang minjie"
date: "`r format(Sys.Date())`"
output:
  github_document
---


```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidybayes)
library(rstan)
library(loo)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(bayesplot::theme_default())
```


## 13.1 Logistic regression with a single predictor
```{r}
nes <- read.table("ROS-Examples/NES/data/nes.txt", header = T)
glimpse(nes)
```

```{r}
df <- nes %>% 
  filter(year == 1992, !is.na(rvote), !is.na(dvote),  rvote == 1 | dvote == 1)
df
```





```{r}
df %>% 
  ggplot(aes(x = income, y = rvote)) +
  geom_jitter()
```

数学表达式

$$
\begin{align}
\text{Pr}(y_i = 1) &= p_i \\
\text{logit}(p_i) &= X_i \beta
\end{align}
$$
我更喜欢这种表述
$$
\begin{align}
y &\sim \text{bernoulli}(p_i) \\
p_i & = \text{inv_logit}(\alpha + \beta x)
\end{align}
$$
用Stan语言表达的似然函数
$$
\begin{align}
\texttt{bernoulli}\mathtt{\_}\texttt{logit}\left(y \mid \alpha + \beta x \right)
=
\texttt{bernoulli}\left(y \mid \operatorname{logit}^{-1}(\alpha + \beta x)\right).
\end{align}
$$

Stan代码如下
```{r, warning=FALSE, message=FALSE}
stan_program <- "
data {
  int<lower=0> N;
  vector[N] x;
  int<lower=0,upper=1> y[N];
}
parameters {
  real alpha;
  real beta;
}
model {

  //for (n in 1:N){
  //  y[n] ~ bernoulli(inv_logit(alpha + beta * x[n]));
  //}
  
  // more efficient and arithmetically stable
  y ~ bernoulli_logit(alpha + beta * x);
}
"


stan_data <- list(
   N = nrow(df),
   x = df$income, 
   y = df$rvote
  )

m13.1 <- stan(model_code = stan_program, data = stan_data)
```



```{r}
m13.1 %>% 
  tidybayes::spread_draws(beta) %>% 
  
  ggplot(aes(x = beta)) +
  ggdist::stat_halfeye(.width = c(0.66, 0.95)) + 
  theme_bw() 
```


## 13.3 Predictions and comparisons

```{r, warning=FALSE, message=FALSE}
stan_program <- "
data {
  int<lower=0> N;
  vector[N] x;
  int<lower=0,upper=1> y[N];
  int<lower=0> M;
  vector[M] new_x;  
}
parameters {
  real alpha;
  real beta;
}
model {
  y ~ bernoulli_logit(alpha + beta * x);
}

generated quantities {
  vector[M] y_linpred; 
  vector[M] y_epred; 
  vector[M] y_predict; 
  vector[M] mu = alpha + beta * new_x;

  for(i in 1:M) {
    y_linpred[i] = mu[i];
    y_epred[i] = inv_logit(mu[i]);
    y_predict[i] = bernoulli_logit_rng(mu[i]);
  }
   
}
"


newdata <- tibble(
  income = 1:5
)


stan_data <- list(
      N      = nrow(df),
      x      = df$income, 
      y      = df$rvote,
      new_x  = newdata$income,
      M      = length(newdata$income)
  )

m13.1a <- stan(model_code = stan_program, data = stan_data)
```


```{r}
m13.1a
```

### using brms
```{r}
library(brms)
brms_logit <- brm(
  rvote | trials(1) ~ income,
  family = binomial(link = "logit"),
  data = df
  )
```

```{r}
brms_logit %>% brms::posterior_linpred(newdata = newdata) # return 4000 * 5 matrix
brms_logit %>% brms::posterior_epred(newdata = newdata)   # return 4000 * 5 matrix
brms_logit %>% brms::posterior_predict(newdata = newdata) # return 4000 * 5 matrix
```



```{r}
brms_logit %>% 
  tidybayes::linpred_draws(
    newdata = newdata
  ) %>% 
  tidybayes::mean_hdi()
```

```{r}
brms_logit %>% 
  tidybayes::epred_draws(
    newdata = newdata
  ) %>% 
  tidybayes::mean_hdi()
```

```{r}
brms_logit %>% 
  tidybayes::predicted_draws( # 输出 0, 1, 1 ... 
    newdata = newdata
  ) %>% 
  tidybayes::mean_hdi()       # 统计均值
```

### using stan_glm()
```{r}
library(rstanarm)
fit_1 <- stan_glm(
  rvote ~ 1 + income, 
  family = binomial(link = "logit"),
  data = df
  )

fit_1
```


```{r, eval=FALSE}
fit_1 %>% rstanarm::posterior_linpred(newdata = newdata) # return 4000 * 5 matrix
fit_1 %>% rstanarm::posterior_epred(newdata = newdata)   # return 4000 * 5 matrix
fit_1 %>% rstanarm::posterior_predict(newdata = newdata) # return 4000 * 5 matrix
```

```{r}
epred <- fit_1 %>% 
  rstanarm::posterior_epred(newdata = newdata)
```

最有钱的人群`level = 5` 与 第二有钱的人群`level =4`，支持bush的概率差
```{r}
mean(epred[, 5] > epred[, 4])
quantile(epred[, 5] - epred[, 4], c(0.025, 0.975))
```


```{r}
fit_1 %>% 
  tidybayes::linpred_draws(
    newdata = newdata
  ) %>% 
  tidybayes::mean_hdi()
```

```{r}
fit_1 %>% 
  tidybayes::epred_draws(
    newdata = newdata
  ) %>% 
  tidybayes::mean_hdi()
```

```{r}
fit_1 %>% 
  tidybayes::predicted_draws( # 输出 0, 1, 1 ... 
    newdata = newdata
  ) %>% 
  tidybayes::mean_qi()        # 统计均值
```

感觉 `brms` 与 `rstanarm` 各搞一套，最后被 `tidybayes` 一统江湖，回归到`tidyverse`框架。但我最喜欢的还是用Stan。





## 13.4 Latent-data formulation

使用隐变量公式，每一个$y_i$ 对应着一个隐变量$z_i$

$$
\begin{align*}
y_i & = \left \{
 \begin{array}{@{}ll@{}}
   1 & \text{if}\ z_i > 0 \\
   0 & \text{if}\ z_i < 0
 \end{array} \right. \\
z_i & = X_i \beta + \epsilon_i, 
\end{align*}
$$
这里独立的误差项$\epsilon_i$服从*logistic* 密度分布。

$$
\operatorname{Pr}(\epsilon_i < x) = \operatorname{logit}^{-1} (x)\ \text{for all}\ x.
$$


原书中图13.5给出了*logistic* 密度分布的图形


```{r, fig.height = 3, fig.width = 5.5}
tibble(x = seq(from = -7, to = 7, length.out = 200)) %>% 
  mutate(d = dlogis(x, location = 0, scale = 1)) %>% 
  
  ggplot(aes(x = x, y = d)) +
  geom_line() +
  scale_x_continuous(NULL, breaks = -3:3 * 2, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(subtitle = "Logistic probability density function")
```



$$
\operatorname{Pr}(y_i = 1) = \operatorname{Pr}(z_i > 0) = \operatorname{Pr}(\epsilon_i > -X_i \beta) = \operatorname{logit}^{-1}(X_i \beta)
$$ 

图13.6 给出了当线性组合 $X_i \beta$等于 -1.07时，隐变量$z_i$的概率密度，它对应图中的灰色区域。


```{r, fig.height = 3, fig.width = 5.5}
tibble(x = seq(from = -7, to = 7, length.out = 201)) %>% 
  mutate(d = dlogis(x, location = -1.07, scale = 1)) %>% 
  
  ggplot(aes(x = x, y = d)) +
  geom_ribbon(aes(ymin = 0, ymax = d, fill = x > 0)) +
  geom_line() +
  scale_fill_manual(values = c("white", "grey67"), breaks = NULL) +
  scale_x_continuous(NULL, breaks = -3:3 * 2, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = expansion(mult = c(0, 0.05))) +
  labs(subtitle = "Latent variable formulation of logit")
```

可以使用`invlogit()`函数计算灰色区域代表的隐变量$z_i$的概率密度

$$
\operatorname{Pr}(y_i = 1) = \operatorname{Pr}(z_i > 0) = \operatorname{Pr}(\epsilon_i > -X_i \beta) = \operatorname{logit}^{-1}(X_i \beta)
$$ 


```{r}
logit <- qlogis 
invlogit <- plogis

invlogit(-1.07)
```
